version: 2.1

# Common executor configuration
executors:
  clojure-java-11:
    docker:
      - image: cimg/clojure:1.11.1-openjdk-11.0
    working_directory: ~/repo


# Job definitions
jobs:
  style:
    executor: clojure-java-11
    steps:
      - checkout
      - run:
          name: Install cljstyle
          environment:
            CLJSTYLE_VERSION: 0.16.626
          command: |
            wget https://github.com/greglook/cljstyle/releases/download/${CLJSTYLE_VERSION}/cljstyle_${CLJSTYLE_VERSION}_linux_amd64.zip
            unzip cljstyle_${CLJSTYLE_VERSION}_linux_amd64.zip
      - run:
          name: Check source formatting
          command: "./cljstyle check --report"

  test-spark-3-1-java-11:
    executor: clojure-java-11
    steps:
      - checkout
      - restore_cache:
          keys:
            - v1-test-spark-3.1-java-11-{{ checksum "project.clj" }}
            - v1-test-spark-3.1-java-11-
      - run:
          name: Test projects
          command: |
            lein -version
            lein monolith each do clean, check, install, test
      - save_cache:
          key: v1-test-{{ checksum "project.clj" }}
          paths:
            - ~/.m2

  test-spark-3-5-java-11:
    executor: clojure-java-11
    steps:
      - checkout
      - restore_cache:
          keys:
            - v1-test-spark-3.5-java-11-{{ checksum "project.clj" }}
            - v1-test-spark-3.5-java-11-
      - run:
          name: Test projects
          command: |
            lein -version
            lein monolith each with-profile -spark-3.1,+spark-3.5 do clean, check, install, test
      - save_cache:
          key: v1-test-spark-3.5-java-11-{{ checksum "project.clj" }}
          paths:
            - ~/.m2

  coverage:
    executor: clojure-java-11
    steps:
      - checkout
      - restore_cache:
          keys:
            - v1-coverage-{{ checksum "project.clj" }}
            - v1-coverage-
            - v1-test-
      - run:
          name: Install projects
          command: lein monolith each install
      - run:
          name: Generate coverage
          command: lein monolith each :in sparkplug-core with-profile +spark-3.1 cloverage --codecov
      - save_cache:
          key: v1-coverage-{{ checksum "project.clj" }}
          paths:
            - ~/.m2
      - store_artifacts:
          path: target/coverage
          destination: coverage
      - run:
          name: Install codecov
          command: |
            sudo apt-get update && sudo apt-get install gpg
            curl https://keybase.io/codecovsecurity/pgp_keys.asc | gpg --no-default-keyring --keyring trustedkeys.gpg --import
            curl -Os https://uploader.codecov.io/latest/linux/codecov
            curl -Os https://uploader.codecov.io/latest/linux/codecov.SHA256SUM
            curl -Os https://uploader.codecov.io/latest/linux/codecov.SHA256SUM.sig
            gpgv codecov.SHA256SUM.sig codecov.SHA256SUM
            shasum -a 256 -c codecov.SHA256SUM
            chmod +x codecov
      - run:
          name: Publish coverage report
          command: './codecov -f target/coverage/codecov.json'


# Workflow definitions
workflows:
  version: 2
  build:
    jobs:
      - style
      - test-spark-3-1-java-11
      - test-spark-3-5-java-11
      - coverage:
          requires:
            - test-spark-3-5-java-11
