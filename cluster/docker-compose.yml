version: "3"
services:
  master:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        HADOOP_VERSION: 2.9.2
        SPARK_VERSION: 2.4.4
        SPARK_VARIANT: without-hadoop-scala-2.12
    command: sbin/start-master.sh
    restart: on-failure
    hostname: master
    environment:
      SPARK_PUBLIC_DNS: localhost
      SPARK_MASTER_PORT: 7077
      SPARK_MASTER_WEBUI_PORT: 8080
    expose:
      - 6066
      - 7001
      - 7002
      - 7003
      - 7004
      - 7005
      - 7006
      - 7077
    ports:
      - 6066:6066
      - 7077:7077
      - 8080:8080
    volumes:
      - ./jars:/mnt/jars

  worker-1:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        HADOOP_VERSION: 2.9.2
        SPARK_VERSION: 2.4.4
        SPARK_VARIANT: without-hadoop-scala-2.12
    command: sbin/start-slave.sh spark://master:7077
    restart: on-failure
    hostname: worker-1
    environment:
      SPARK_PUBLIC_DNS: localhost
      SPARK_WORKER_PORT: 8881
      SPARK_WORKER_WEBUI_PORT: 8081
      SPARK_WORKER_CORES: 2
      SPARK_WORKER_MEMORY: 2g
    links:
      - master
    depends_on:
      - master
    expose:
      - 4040
      - 7012
      - 7013
      - 7014
      - 7015
      - 7016
      - 8881
    ports:
      - 4040:4040
      - 8081:8081
      - 8881:8881
    volumes:
      - ./jars:/mnt/jars
      - ./data:/data

  repl:
    image: java:8-jre-alpine
    command: java -jar /sparkplug-repl.jar
    restart: on-failure
    hostname: repl
    environment:
      SPARKPLUG_REPL_MASTER: spark://master:7077
      SPARKPLUG_REPL_PORT: 8765
    ports:
      - 4050:4040
      - 8765:8765
    volumes:
      - ./jars/sparkplug-repl.jar:/sparkplug-repl.jar
      - ./data:/data

networks:
  default:
    ipam:
      config:
        - subnet: "10.128.99.0/24"
